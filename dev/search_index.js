var documenterSearchIndex = {"docs":
[{"location":"howto.html#TextAssociations","page":"Guided Examples","title":"TextAssociations","text":"","category":"section"},{"location":"howto.html","page":"Guided Examples","title":"Guided Examples","text":"Documentation for TextAssociations.","category":"page"},{"location":"howto.html#Guide","page":"Guided Examples","title":"Guide","text":"","category":"section"},{"location":"theory.html#TextAssociations","page":"Theory","title":"TextAssociations","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Documentation for TextAssociations.","category":"page"},{"location":"theory.html#Association-metrics","page":"Theory","title":"Association metrics","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"TextAssociations.jl implements the list of all association measures from Pecina's paper.","category":"page"},{"location":"theory.html#Association-Measures","page":"Theory","title":"Association Measures","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Joint probability\nConditional probability\nReverse conditional probability\nMutual dependency\nLog frequency biased mutual dependency\nNormalized expectation\nMutual expectation\nSalience\nPearson's chitest\nSquared log likelihood ratio\nFirst Kulczynsky\nFager\nUnigram subtuples\nU cost\nS cost\nR cost\nT combined cost\nKappa\nJ-measure\nGini index\nConfidence\nLaplace\nConviction\nCertainity\nAdded value\nCollective\nKlosgen","category":"page"},{"location":"theory.html#Dependency-Measures","page":"Theory","title":"Dependency Measures","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Pointwise mutual information\nLog frequency biased mutual dependency\nNormalized expectation\nMutual expectation\nSalience","category":"page"},{"location":"theory.html#Similarity-Measures","page":"Theory","title":"Similarity Measures","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Jaccard\nSokal-Michener\nRussel-Rao\nHamann\nPointwise mutual information\nLog likelihood ratio\nPhi coefficient\nRogers-Tanimoto\nSecond Kulczynski","category":"page"},{"location":"theory.html#Correlation-Measures","page":"Theory","title":"Correlation Measures","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Pearson","category":"page"},{"location":"theory.html#Statistical-Tests","page":"Theory","title":"Statistical Tests","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"t test\nz score\nPoison significance measure\nFisher's exact test","category":"page"},{"location":"theory.html#Coefficients-and-Indices","page":"Theory","title":"Coefficients and Indices","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Yule's omega\nDriver-Kroeber\nFifth Sokal-Sneath\nThird Sokal-Sneath\nSecond Sokal-Sneath\nFourth Sokal-Sneath\nPiatersky-Shapiro\nOdds ratio\nYule's Q","category":"page"},{"location":"theory.html#Miscellaneous-Measures","page":"Theory","title":"Miscellaneous Measures","text":"","category":"section"},{"location":"theory.html","page":"Theory","title":"Theory","text":"Mountford\nGower","category":"page"},{"location":"reference.html#TextAssociations","page":"API Reference","title":"TextAssociations","text":"","category":"section"},{"location":"reference.html","page":"API Reference","title":"API Reference","text":"Documentation for TextAssociations.","category":"page"},{"location":"reference.html","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"reference.html#TextAssociations.ContingencyTable","page":"API Reference","title":"TextAssociations.ContingencyTable","text":"ContingencyTable <: AssociationDataFormat\n\nA type representing a contingency table for analyzing the context of a target word within a specified window size in a given input string.\n\nFields\n\ncon_tbl::LazyProcess{T, DataFrame}: A lazy process that generates the contingency table when accessed.\nnode::AbstractString: The target word for which the contingency table is generated.\nwindowsize::Int: The window size around the target word to consider for context.\nminfreq::Int64: The minimum frequency threshold for including words in the contingency table.\n\nConstructors\n\nContingencyTable(inputstring::AbstractString, node::AbstractString, windowsize::Int, minfreq::Int64=5; auto_prep::Bool=true)\nCreates a new ContingencyTable instance.\ninputstring::AbstractString: The input text to be analyzed.\nnode::AbstractString: The target word for which the contingency table will be generated.\nwindowsize::Int: The window size around the target word to consider for context.\nminfreq::Int64: The minimum frequency threshold for including words in the contingency table (default: 5).\nauto_prep::Bool: If true, preprocesses the input string before analysis (default: true).\n\nExample\n\ninputstring = \"This is a sample text where the target word appears multiple times. The target word is analyzed for context.\"\nnode = \"target\"\nwindowsize = 5\nminfreq = 2\n\ncont_table = ContingencyTable(inputstring, node, windowsize, minfreq)\n\n\n\n\n\n","category":"type"},{"location":"reference.html#TextAssociations.conttbl","page":"API Reference","title":"TextAssociations.conttbl","text":"conttbl(input_string::StringDocument{String}, target_word::AbstractString, windowsize::Int64=5, minfreq::Int64=3)\n\nGenerate a contingency table for a target word in a given text document, analyzing its surrounding context within a specified window size.\n\nArguments\n\ninput_string::StringDocument{String}: The input text document to be analyzed, represented as a StringDocument from the TextAnalysis package.\ntarget_word::AbstractString: The word for which the context analysis is to be performed.\nwindowsize::Int64=5: The number of words to consider on either side of the target word for context (default is 5).\nminfreq::Int64=3: The minimum frequency threshold for words to be included in the contingency table (default is 3).\n\nReturns\n\nA DataFrame containing the contingency table with columns:\nCollocate: The context word.\na: Frequency of the context word in the target window.\nb: Frequency of the context word outside the target window but in the document.\nc: Frequency of other words in the target window.\nd: Frequency of other words outside the target window but in the document.\nm: The total frequency of the collocate word in the document (m = a + b).\nn: The total frequency of all other words in the document (n = c + d).\nk: The total frequency of words in the window (k = a + c).\nl: The total frequency of words outside the window (l = b + d).\nN: The total number of words in the document (N = m + n).\nE₁₁: The expected frequency of the collocate word in the window under the assumption of independence: E₁₁ = (m * k) / N\nE₁₂: The expected frequency of the collocate word outside the window: E₁₂ = (m * l) / N\nE₂₁: The expected frequency of other words in the window: E₂₁ = (n * k) / N\nE₂₂: The expected frequency of other words outside the window: E₂₂ = (n * l) / N\n\nDescription\n\nThe conttbl function processes a StringDocument, tokenizes the text, and identifies the indices of the target word. It then collects context words within a specified window size around each occurrence of the target word. The function calculates the frequency of these context words and constructs a contingency table. The table includes the frequency of context words inside and outside the target window and computes various statistical measures used for further linguistic analysis.\n\nExample\n\nusing TextAnalysis, DataFrames, Chain\n\ndoc = StringDocument(\"This is a sample text document for testing the contingency table function. This function will analyze the text and provide useful statistics.\")\nconttbl(doc, \"text\", 5, 3)\n\nNotes\n\nThe function assumes that the input text is preprocessed and tokenized correctly.\n\nEnsure that the TextAnalysis package is properly imported and used for StringDocument and tokenization.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.count_substrings-Tuple{String, String}","page":"API Reference","title":"TextAssociations.count_substrings","text":"count_substring_regex_optimized(text::String, substring::String) -> Int\ncount_substrings(text::String, substrings::Vector{String}) -> Dict{String, Int}\n\nCount the number of occurrences of one or more substrings within a given text using regular expressions.\n\nMethods\n\nSingle Substring\n\ncount_substring_regex_optimized(text::String, substring::String) -> Int\n\nCount the number of occurrences of a single substring within the text.\n\nArguments\n\ntext::String: The text in which to search for the substring.\nsubstring::String: The substring to count within the text.\n\nReturns\n\nInt: The number of times the substring appears in the text.\n\nExample\n\ntext = \"hello world, hello universe\"\nsubstring = \"hello\"\ncount = count_substring_regex_optimized(text, substring)\nprintln(count)  # Output: 2\n\nMultiple Substrings\n\ncount_substrings(text::String, substrings::Vector{String}) -> Dict{String, Int}\n\nCount the number of occurrences of each substring in a given vector within the larger string. \n\nArguments\n\ntext::String: The text in which to search for the substrings.\nsubstrings::Vector{String}: A vector of substrings to count within the text.\n\nReturns\n\nDict{String, Int}: A dictionary where keys are substrings and values are their respective counts in the laeger string.\n\nExample\n\ntext = \"hello world, hello universe\"\nsubstrings = [\"hello\", \"world\"]\ncounts = count_substrings(text, substrings)\nprintln(counts)  # Output: Dict(\"hello\" => 2, \"world\" => 1)\n\nDescription\n\nThese methods utilize regular expressions to efficiently find and count all non-overlapping occurrences of one or more substrings within the provided text. The single substring function returns an integer count, while the multiple substrings function returns a dictionary of counts.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.eval_attrrisk","page":"API Reference","title":"TextAssociations.eval_attrrisk","text":"Compute the Attributable Risk for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of AttrRisk scores.\n\nFormula\n\ntextAttributable Risk = fracam - fraccn\n\nUsage\n\neval_attrrisk(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_dice","page":"API Reference","title":"TextAssociations.eval_dice","text":"Compute the Dice Coefficient for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of Dice scores.\n\nFormula\n\ntextDice = frac2am + k\n\nUsage\n\neval_dice(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_jaccardidx","page":"API Reference","title":"TextAssociations.eval_jaccardidx","text":"Compute the Jaccard Index for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of JaccardIdx scores.\n\nFormula\n\ntextJaccard Index = fracaa + b + c\n\nUsage\n\neval_jaccardindex(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_logdice","page":"API Reference","title":"TextAssociations.eval_logdice","text":"Compute Log Dice for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of LogDice scores.\n\nFormula\n\ntextLogDice = 14 + log_2left(frac2am + kright)\n\nUsage\n\neval_logdice(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_logoddsratio","page":"API Reference","title":"TextAssociations.eval_logoddsratio","text":"Compute the Log Odds Ratio for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of LogOddsRatio scores.\n\nFormula\n\nlog(textOR) = logleft(fraca cdot db cdot cright)\n\nUsage\n\neval_logoddsratio(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_logrelrisk","page":"API Reference","title":"TextAssociations.eval_logrelrisk","text":"Compute the Log Relative Risk for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of LogRelRisk scores.\n\nFormula\n\nlog(textRR) = logleft(fracamright) - logleft(fraccnright)\n\nUsage\n\neval_logrelrisk(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_ochiaiidx","page":"API Reference","title":"TextAssociations.eval_ochiaiidx","text":"Compute the Ochiai Index for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of OchiaiIdx scores.\n\nFormula\n\ntextOchiai Index = fracasqrt(a + b)(a + c)\n\nUsage\n\neval_ochiaiindex(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_oddsratio","page":"API Reference","title":"TextAssociations.eval_oddsratio","text":"Compute the Odds Ratio for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of OddsRatio scores.\n\nFormula\n\ntextOR = fraca cdot db cdot c\n\nUsage\n\neval_oddsratio(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_pmi","page":"API Reference","title":"TextAssociations.eval_pmi","text":"Compute Pointwise Mutual Information (PMI) for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of PMI scores.\n\nFormula\n\ntextPMI(a b) = log_2left(fracP(a b)P(a)P(b)right)\n\nUsage\n\neval_pmi(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_ppmi","page":"API Reference","title":"TextAssociations.eval_ppmi","text":"Compute Positive Pointwise Mutual Information (PPMI) for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of PPMI scores.\n\nFormula\n\ntextPPMI(a b) = max(0 textPMI(a b))\n\nUsage\n\neval_ppmi(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_relrisk","page":"API Reference","title":"TextAssociations.eval_relrisk","text":"Compute the Relative Risk (RR) for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of RelRisk scores.\n\nFormula\n\ntextRR = fracfracamfraccn\n\nUsage\n\neval_relrisk(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.eval_riskdiff","page":"API Reference","title":"TextAssociations.eval_riskdiff","text":"Compute the Risk Difference for a given contingency table.\n\nArguments\n\ndata::ContingencyTable: The contingency table to evaluate.\n\nReturns\n\nArray: An array of RiskDiff scores.\n\nFormula\n\ntextRisk Difference = fracam - fraccn\n\nUsage\n\neval_riskdiff(cont_tbl)\n\n\n\n\n\n","category":"function"},{"location":"reference.html#TextAssociations.evalassoc-Tuple{Type{<:AssociationMetric}, Union{AbstractString, ContingencyTable}}","page":"API Reference","title":"TextAssociations.evalassoc","text":"evalassoc(metricType::Type{<:AssociationMetric}, cont_tbl::ContingencyTable)\n\nEvaluate an association metric based on the provided metric type and a contingency table. This function dynamically dispatches the calculation to the appropriate function determined by metricType.\n\nArguments\n\nmetrics::Array{<:AssociationMetric}: An array of association metric types to evaluate.\ndata::ContingencyTable: The contingency table data on which to evaluate the metrics. To create one, use the ContingencyTable constructor. \n\nReturns\n\nA Vector of numerical values where each value represents the association metric score of the node word picked when creating the ContingencyTable with each of the co-occurring words in the window length picked when creating the ContingencyTable. \n\nUsage\n\nresult = evalassoc(MetricType, cont_tbl)\n\nReplace MetricType with the desired association metric type (e.g., PMI, Dice) and cont_tbl with your contingency table. You can see all supported metrics through listmetrics().\n\nExamples\n\nPMI (Pointwise Mutual Information):\n\nresult = evalassoc(PMI, cont_tbl)\n\nDice Coefficient:\n\nresult = evalassoc(Dice, cont_tbl)\n\nFurther Reading\n\nFor detailed mathematical definitions and discussion on each metric, refer to our documentation site.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.evalassoc-Tuple{Vector{DataType}, Union{AbstractString, ContingencyTable}}","page":"API Reference","title":"TextAssociations.evalassoc","text":"evalassoc(metrics::Array{<:AssociationMetric}, cont_tbl::ContingencyTable)\n\nEvaluate an array of association metrics on the given contingency table.\n\nArguments\n\nmetrics::Array{<:AssociationMetric}: An array of association metric types to evaluate.\ndata::ContingencyTable: The contingency table data on which to evaluate the metrics.\n\nReturns\n\nA DataFrame where each column represents an evaluation result for a corresponding metric.\n\nUsage\n\nresult = evalassoc([MetricType1, MetricType2, MetricType3, ...], cont_tbl)\n\nReplace MetricType$ with the desired association metric types (e.g., PMI, Dice) and cont_tbl with your contingency table. You can see all supported metrics through listmetrics().\n\nExamples\n\nPMI (Pointwise Mutual Information) and Dice Coefficient returned within two columns of the DataFrame result below.\n\nevalassoc(Metrics([PMI, Dice]), cont_to)\n\nn×2 DataFrame\n Row │ PMI  Dice  \n     │ Float64   Float64 \n─────┼─────────────────\n   1 │ 0.2\t\t0.4 \t\t\n   2 | 0.3\t\t0.3 \t\t\n   3 | 0.1 \t\t0.5 \t\t\n   4 | 0.7\t\t0.6\t\t\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.extract_cached_data-Union{Tuple{LazyProcess{T, R}}, Tuple{R}, Tuple{T}} where {T, R}","page":"API Reference","title":"TextAssociations.extract_cached_data","text":"extract_cached_data(z::LazyProcess{T})\n\nIntermediate function for the LazyProcess type. If the cached_process is false then the function f() will be called and the result will be stored in cached_result and cached_process will be set to true. If cached_process is true then the cached_result will be returned (which is either a Cooccurrence Matrix or a Dictionary with words as keys and frequencies as their values).\n\nExample\n\njulia> doc = StringDocument(\"This is a text about an apple. There are many texts about apples.\");\n       z = CachedData(doc, 2, :default)\n       extract_cached_data(z)\n2.0\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.find_prior_words-Tuple{TextAnalysis.StringDocument, String, Int64}","page":"API Reference","title":"TextAssociations.find_prior_words","text":"find_prior_words(strdoc::StringDocument, substring::String, n::Int) -> Tuple{Set{String}, Int64}\n\nFind the unique words that appear n words before each match of the given substring within a larger string, and return the set of unique words along with its length.\n\nArguments\n\nstrdoc::StringDocument: The text document in which to search for the substring.\nsubstring::String: The substring to search within the text.\nn::Int: The number of words to look back before each match.\n\nReturns\n\nTuple{Set{String}, Int64}: A tuple containing:\nA set of unique words that appear n words before each match of the given substring.\nThe number of unique words in the set.\n\nExample\n\nstrdoc = StringDocument(\"Γρήγορη καφέ αλεπού πηδάει πάνω από τον τεμπέλη σκύλο. Η γρήγορη καφέ αλεπού είναι πολύ γρήγορη.\")\nsubstring = \"γρήγορη\"\nn = 2\nunique_prior_words, count = find_prior_words(strdoc, substring, n)\nprintln(unique_prior_words)  # Output: Set([\"Η\", \"καφέ\", \"από\"])\nprintln(count)  # Output: 3\n\nDescription\n\nThis function utilizes regular expressions to find the substring within the text and then identifies the unique words that appear n words before each match. It handles Unicode boundaries correctly to ensure valid indexing and processes the text to strip punctuation, whitespace, and normalize case.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.listmetrics-Tuple{}","page":"API Reference","title":"TextAssociations.listmetrics","text":"listmetrics() -> Vector{Symbol}\n\nReturns a list of all association metrics supported by the package. This function provides an easy way for users to discover and understand the different types of metrics they can calculate using the package.\n\nReturns\n\nVector{Symbol}: A vector containing the symbols representing each of the supported association metrics.\n\nExamples\n\nmetricsvector = listmetrics()\nprintln(metricsvector)\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.log_safe-Tuple{Real}","page":"API Reference","title":"TextAssociations.log_safe","text":"log_safe(x::Real) -> Real\n\nComputes the logarithm of x, ensuring numerical stability by replacing zero or negative values with a small positive value (eps()).\n\nArguments\n\nx::Real: The input value for the logarithm.\n\nReturns\n\nReal: The logarithm of x if x > 0, otherwise the logarithm of eps().\n\nExamples\n\n```julia logsafe(0.1)    # Returns log(0.1) logsafe(0)      # Returns log(eps())\n\n\n\n\n\n","category":"method"},{"location":"reference.html#TextAssociations.prepstring-Tuple{AbstractString}","page":"API Reference","title":"TextAssociations.prepstring","text":"prepstring(input_path::AbstractString)\n\nPrepare and preprocess a text document, a corpus of text documents or a plain raw string.\n\nArguments\n\ninput_path::AbstractString: The path to a text file, a directory containing text files, or a raw text string. \nIf input_path is a path to a text file, the function reads and preprocesses the content of the file.\nIf input_path is a path to a directory, the function reads and preprocesses the content of all .txt files in the directory.\nIf input_path is a raw text string, the function preprocesses the string directly.\n\nReturns\n\nA StringDocument object with normalized text data.\n\nPreprocessing Steps\n\nThe function performs the following preprocessing steps on the text:\n\nStrips punctuation\nStrips whitespace\nConverts text to lowercase\n\nExamples\n\n# Process a single text file\ndoc = prepstring(\"path/to/textfile.txt\")\n\n# Process a directory of text files\ndocs = prepstring(\"path/to/directory\")\n\n# Process a raw string\ntext_string = prepstring(\"This is a raw string.\")\n\nErrors\n\nThrows an ArgumentError if input_path is not a valid file path, a directory path, or a raw string.\n\nNotes\n\nThe function assumes that text files in the directory have a .txt extension.\nThe maximum length for the input path is set to 256 characters to comply with Windows file path limits.\n\n\n\n\n\n","category":"method"},{"location":"index.html#TextAssociations","page":"Intro","title":"TextAssociations","text":"","category":"section"},{"location":"index.html","page":"Intro","title":"Intro","text":"Documentation for TextAssociations.","category":"page"},{"location":"index.html#Install","page":"Intro","title":"Install","text":"","category":"section"},{"location":"index.html","page":"Intro","title":"Intro","text":"julia> add https://github.com/atantos/TextAssociations.jl","category":"page"},{"location":"tutorial.html#TextAssociations","page":"Quick Start","title":"TextAssociations","text":"","category":"section"},{"location":"tutorial.html","page":"Quick Start","title":"Quick Start","text":"Documentation for TextAssociations.","category":"page"},{"location":"tutorial.html#Basics","page":"Quick Start","title":"Basics","text":"","category":"section"}]
}
